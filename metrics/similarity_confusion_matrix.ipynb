{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix for Similarity Matching Model\n",
    "\n",
    "This notebook creates a confusion matrix to evaluate the OpenCV similarity matching model performance on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define CV2SimilarityClassifier Class\n",
    "\n",
    "This class needs to be defined to unpickle the saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV2SimilarityClassifier class defined!\n"
     ]
    }
   ],
   "source": [
    "class CV2SimilarityClassifier:\n",
    "    \"\"\"\n",
    "    Classifier using OpenCV's template matching and feature matching.\n",
    "    Uses multiple similarity metrics from cv2.\n",
    "    This class needs to be defined here so pickle can load saved models.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, method='multi'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            method: 'template' (cv2.matchTemplate), 'features' (keypoint matching), \n",
    "                   'histogram' (histogram comparison), or 'multi' (combines all)\n",
    "        \"\"\"\n",
    "        self.method = method\n",
    "        self.templates = {}\n",
    "        self.classes_ = None\n",
    "        \n",
    "        # Initialize feature detectors\n",
    "        if method in ['features', 'multi']:\n",
    "            try:\n",
    "                # Try SIFT first (better but requires opencv-contrib-python)\n",
    "                self.detector = cv2.SIFT_create()\n",
    "                self.matcher = cv2.BFMatcher()\n",
    "            except:\n",
    "                # Fall back to ORB (built-in)\n",
    "                self.detector = cv2.ORB_create()\n",
    "                self.matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    \n",
    "    def _template_match_score(self, img, template):\n",
    "        \"\"\"Use cv2.matchTemplate with multiple methods.\"\"\"\n",
    "        # Normalize images\n",
    "        img_norm = cv2.normalize(img.astype(np.float32), None, 0, 1, cv2.NORM_MINMAX)\n",
    "        template_norm = cv2.normalize(template.astype(np.float32), None, 0, 1, cv2.NORM_MINMAX)\n",
    "        \n",
    "        # Try different matching methods\n",
    "        methods = [\n",
    "            cv2.TM_CCOEFF_NORMED,  # Normalized correlation coefficient\n",
    "            cv2.TM_CCORR_NORMED,   # Normalized cross-correlation\n",
    "        ]\n",
    "        \n",
    "        scores = []\n",
    "        for method in methods:\n",
    "            result = cv2.matchTemplate(img_norm, template_norm, method)\n",
    "            scores.append(np.max(result))\n",
    "        \n",
    "        return np.mean(scores)\n",
    "    \n",
    "    def _feature_match_score(self, img, template_data):\n",
    "        \"\"\"Match using keypoint features.\"\"\"\n",
    "        kp_img, desc_img = self.detector.detectAndCompute(img, None)\n",
    "        \n",
    "        if desc_img is None or len(kp_img) < 4:\n",
    "            return 0.0\n",
    "        \n",
    "        best_matches = []\n",
    "        for desc_template in template_data.get('descriptors', []):\n",
    "            if desc_template is None:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Check if matcher has getCrossCheck method (ORB)\n",
    "                if hasattr(self.matcher, 'getCrossCheck') and self.matcher.getCrossCheck():\n",
    "                    # ORB with Hamming distance\n",
    "                    matches = self.matcher.match(desc_img, desc_template)\n",
    "                    matches = sorted(matches, key=lambda x: x.distance)\n",
    "                    best_matches.extend(matches[:20])  # Top 20 matches\n",
    "                else:\n",
    "                    # SIFT with ratio test\n",
    "                    matches = self.matcher.knnMatch(desc_img, desc_template, k=2)\n",
    "                    good_matches = []\n",
    "                    for match_pair in matches:\n",
    "                        if len(match_pair) == 2:\n",
    "                            m, n = match_pair\n",
    "                            if m.distance < 0.75 * n.distance:  # Lowe's ratio test\n",
    "                                good_matches.append(m)\n",
    "                    best_matches.extend(good_matches)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if len(best_matches) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # Score based on number of good matches\n",
    "        match_score = len(best_matches) / max(len(kp_img), 1)\n",
    "        return min(match_score, 1.0)\n",
    "    \n",
    "    def _histogram_match_score(self, img, template):\n",
    "        \"\"\"Compare histograms using multiple methods.\"\"\"\n",
    "        # Calculate histograms\n",
    "        hist_img = cv2.calcHist([img], [0], None, [256], [0, 256])\n",
    "        hist_template = cv2.calcHist([template], [0], None, [256], [0, 256])\n",
    "        \n",
    "        # Normalize\n",
    "        cv2.normalize(hist_img, hist_img, 0, 1, cv2.NORM_MINMAX)\n",
    "        cv2.normalize(hist_template, hist_template, 0, 1, cv2.NORM_MINMAX)\n",
    "        \n",
    "        # Compare using multiple methods\n",
    "        methods = [\n",
    "            cv2.HISTCMP_CORREL,      # Correlation\n",
    "            cv2.HISTCMP_INTERSECT,   # Intersection\n",
    "            cv2.HISTCMP_BHATTACHARYYA # Bhattacharyya distance\n",
    "        ]\n",
    "        \n",
    "        scores = []\n",
    "        for method in methods:\n",
    "            score = cv2.compareHist(hist_img, hist_template, method)\n",
    "            if method == cv2.HISTCMP_BHATTACHARYYA:\n",
    "                # Lower is better for Bhattacharyya, convert to similarity\n",
    "                score = 1.0 - min(score, 1.0)\n",
    "            scores.append(score)\n",
    "        \n",
    "        return np.mean(scores)\n",
    "    \n",
    "    def _compute_similarity(self, img, template_data):\n",
    "        \"\"\"Compute similarity using selected method(s).\"\"\"\n",
    "        template = template_data['mean']\n",
    "        scores = []\n",
    "        \n",
    "        if self.method in ['template', 'multi']:\n",
    "            scores.append(self._template_match_score(img, template))\n",
    "        \n",
    "        if self.method in ['features', 'multi']:\n",
    "            scores.append(self._feature_match_score(img, template_data))\n",
    "        \n",
    "        if self.method in ['histogram', 'multi']:\n",
    "            scores.append(self._histogram_match_score(img, template))\n",
    "        \n",
    "        return np.mean(scores) if scores else 0.0\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class for each image in X.\"\"\"\n",
    "        predictions = []\n",
    "        for img in X:\n",
    "            similarities = {}\n",
    "            for cls_idx in self.classes_:\n",
    "                template_data = self.templates[cls_idx]\n",
    "                similarity = self._compute_similarity(img, template_data)\n",
    "                similarities[cls_idx] = similarity\n",
    "            \n",
    "            # Get class with highest similarity\n",
    "            predicted_class = max(similarities, key=similarities.get)\n",
    "            predictions.append(predicted_class)\n",
    "        \n",
    "        return np.array(predictions)\n",
    "\n",
    "print(\"CV2SimilarityClassifier class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Model and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Configuration:\n",
      "  Image size: 64x64\n",
      "  Number of classes: 340\n",
      "  Method: multi\n",
      "  Use Sobel: True\n",
      "  Test accuracy (from training): 0.162\n",
      "✓ Using SIFT detector\n",
      "\n",
      "✓ Model loaded successfully from models/similarity/classifier.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load model info and label mappings\n",
    "model_dir = Path('./models/similarity')\n",
    "\n",
    "# Load model info\n",
    "with open(model_dir / 'model_info.json', 'r') as f:\n",
    "    model_info = json.load(f)\n",
    "\n",
    "# Load label mappings\n",
    "with open(model_dir / 'label_mappings.json', 'r') as f:\n",
    "    label_mappings = json.load(f)\n",
    "\n",
    "# Extract information\n",
    "idx_to_label = {int(k): v for k, v in label_mappings['idx_to_label'].items()}\n",
    "label_to_idx = label_mappings['label_to_idx']\n",
    "num_classes = model_info['num_classes']\n",
    "img_size = model_info.get('image_size', 64)\n",
    "use_sobel = model_info.get('use_sobel', False)\n",
    "method = model_info.get('method', 'multi')\n",
    "\n",
    "print(f\"\\nModel Configuration:\")\n",
    "print(f\"  Image size: {img_size}x{img_size}\")\n",
    "print(f\"  Number of classes: {num_classes}\")\n",
    "print(f\"  Method: {method}\")\n",
    "print(f\"  Use Sobel: {use_sobel}\")\n",
    "print(f\"  Test accuracy (from training): {model_info.get('accuracy', 'N/A')}\")\n",
    "\n",
    "# Load the classifier from pickle\n",
    "classifier_path = model_dir / 'classifier.pkl'\n",
    "if not classifier_path.exists():\n",
    "    raise FileNotFoundError(f\"Classifier file not found: {classifier_path}\")\n",
    "\n",
    "with open(classifier_path, 'rb') as f:\n",
    "    classifier = pickle.load(f)\n",
    "\n",
    "# Recreate detector and matcher if needed (they might not be pickleable)\n",
    "if method in ['features', 'multi']:\n",
    "    if not hasattr(classifier, 'detector') or classifier.detector is None:\n",
    "        try:\n",
    "            classifier.detector = cv2.SIFT_create()\n",
    "            classifier.matcher = cv2.BFMatcher()\n",
    "            print(\"✓ Using SIFT detector\")\n",
    "        except:\n",
    "            classifier.detector = cv2.ORB_create()\n",
    "            classifier.matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "            print(\"✓ Using ORB detector\")\n",
    "    else:\n",
    "        print(\"✓ Detector already loaded\")\n",
    "\n",
    "print(f\"\\n✓ Model loaded successfully from {classifier_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing functions defined!\n"
     ]
    }
   ],
   "source": [
    "def apply_sobel(img):\n",
    "    \"\"\"Apply Sobel edge detection to an image.\n",
    "    \n",
    "    The Sobel filter detects edges by computing gradients in x and y directions.\n",
    "    This is a classical computer vision technique - the kernel weights are \n",
    "    hand-designed, NOT learned like in CNNs.\n",
    "    \"\"\"\n",
    "    # Sobel kernels for x and y gradients\n",
    "    sobel_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)  # Horizontal edges\n",
    "    sobel_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)  # Vertical edges\n",
    "    \n",
    "    # Compute gradient magnitude\n",
    "    magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "    \n",
    "    # Normalize to 0-255 range\n",
    "    magnitude = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "    return magnitude.astype(np.uint8)\n",
    "\n",
    "def preprocess_image(img_path, image_size, use_sobel=False):\n",
    "    \"\"\"\n",
    "    Load and preprocess an image for similarity matching.\n",
    "    Similarity matching uses grayscale images.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        return None\n",
    "    \n",
    "    # Resize\n",
    "    img = cv2.resize(img, (image_size, image_size))\n",
    "    \n",
    "    # Invert if needed (doodles are typically white on black)\n",
    "    if img.mean() > 127:\n",
    "        img = 255 - img\n",
    "    \n",
    "    # Apply Sobel edge detection if model was trained with it\n",
    "    if use_sobel:\n",
    "        img = apply_sobel(img)\n",
    "    \n",
    "    return img\n",
    "\n",
    "print(\"Preprocessing functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data from 340 categories...\n",
      "Samples per category: 200\n",
      "Using Sobel preprocessing: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading test images:   2%|▏         | 8/340 [00:00<00:39,  8.40it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing Sobel preprocessing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muse_sobel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Load test images\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m X_test_images, y_test_labels, test_paths = \u001b[43mload_test_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_categories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSAMPLES_PER_CATEGORY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_sobel\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Encode labels\u001b[39;00m\n\u001b[32m     52\u001b[39m y_test_encoded = np.array([label_to_idx[label] \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m y_test_labels])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mload_test_images\u001b[39m\u001b[34m(categories, samples_per_category, image_size, use_sobel)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m img_path \u001b[38;5;129;01min\u001b[39;00m image_files:\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m         img = \u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_sobel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     30\u001b[39m             images.append(img)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mpreprocess_image\u001b[39m\u001b[34m(img_path, image_size, use_sobel)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpreprocess_image\u001b[39m(img_path, image_size, use_sobel=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m     21\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[33;03m    Load and preprocess an image for similarity matching.\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[33;03m    Similarity matching uses grayscale images.\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     img = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mIMREAD_GRAYSCALE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     27\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Setup paths\n",
    "doodle_dir = Path('doodles/doodle')\n",
    "\n",
    "# Configuration\n",
    "SAMPLES_PER_CATEGORY = 200  # Number of test samples per category\n",
    "\n",
    "def load_test_images(categories, samples_per_category, image_size, use_sobel=False):\n",
    "    \"\"\"\n",
    "    Load test images from disk and preprocess them for similarity matching.\n",
    "    Similarity matching uses grayscale images.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    image_paths = []\n",
    "    \n",
    "    for category in tqdm(categories, desc=\"Loading test images\"):\n",
    "        if category not in label_to_idx:\n",
    "            continue\n",
    "            \n",
    "        category_path = doodle_dir / category\n",
    "        if not category_path.exists():\n",
    "            continue\n",
    "            \n",
    "        image_files = list(category_path.glob('*.png'))[:samples_per_category]\n",
    "        \n",
    "        for img_path in image_files:\n",
    "            try:\n",
    "                img = preprocess_image(img_path, image_size, use_sobel)\n",
    "                if img is not None:\n",
    "                    images.append(img)\n",
    "                    labels.append(category)\n",
    "                    image_paths.append(str(img_path))\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")\n",
    "    \n",
    "    return np.array(images), np.array(labels), image_paths\n",
    "\n",
    "# Get all categories that are in the model\n",
    "all_categories = sorted([d.name for d in doodle_dir.iterdir() if d.is_dir()])\n",
    "model_categories = [cat for cat in all_categories if cat in label_to_idx]\n",
    "\n",
    "print(f\"Loading test data from {len(model_categories)} categories...\")\n",
    "print(f\"Samples per category: {SAMPLES_PER_CATEGORY}\")\n",
    "print(f\"Using Sobel preprocessing: {use_sobel}\")\n",
    "\n",
    "# Load test images\n",
    "X_test_images, y_test_labels, test_paths = load_test_images(\n",
    "    model_categories, SAMPLES_PER_CATEGORY, img_size, use_sobel\n",
    ")\n",
    "\n",
    "# Encode labels\n",
    "y_test_encoded = np.array([label_to_idx[label] for label in y_test_labels])\n",
    "\n",
    "print(f\"\\nLoaded {len(X_test_images)} test images\")\n",
    "print(f\"Number of classes in test set: {len(np.unique(y_test_encoded))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions on test set...\n",
      "Note: Similarity matching can be slow as it compares each image to all templates.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMaking predictions on test set...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNote: Similarity matching can be slow as it compares each image to all templates.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m y_pred_encoded = \u001b[43mclassifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Calculate accuracy\u001b[39;00m\n\u001b[32m      8\u001b[39m accuracy = accuracy_score(y_test_encoded, y_pred_encoded)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 137\u001b[39m, in \u001b[36mCV2SimilarityClassifier.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cls_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.classes_:\n\u001b[32m    136\u001b[39m     template_data = \u001b[38;5;28mself\u001b[39m.templates[cls_idx]\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     similarity = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m     similarities[cls_idx] = similarity\n\u001b[32m    140\u001b[39m \u001b[38;5;66;03m# Get class with highest similarity\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 123\u001b[39m, in \u001b[36mCV2SimilarityClassifier._compute_similarity\u001b[39m\u001b[34m(self, img, template_data)\u001b[39m\n\u001b[32m    120\u001b[39m     scores.append(\u001b[38;5;28mself\u001b[39m._template_match_score(img, template))\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.method \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mfeatures\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmulti\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m     scores.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_feature_match_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_data\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.method \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mhistogram\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmulti\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m    126\u001b[39m     scores.append(\u001b[38;5;28mself\u001b[39m._histogram_match_score(img, template))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 50\u001b[39m, in \u001b[36mCV2SimilarityClassifier._feature_match_score\u001b[39m\u001b[34m(self, img, template_data)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_feature_match_score\u001b[39m(\u001b[38;5;28mself\u001b[39m, img, template_data):\n\u001b[32m     49\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Match using keypoint features.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     kp_img, desc_img = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdetector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetectAndCompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m desc_img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kp_img) < \u001b[32m4\u001b[39m:\n\u001b[32m     53\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0.0\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Make predictions on test set\n",
    "print(\"Making predictions on test set...\")\n",
    "print(\"Note: Similarity matching can be slow as it compares each image to all templates.\")\n",
    "\n",
    "y_pred_encoded = classifier.predict(X_test_images)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred_encoded)\n",
    "print(f\"\\nTest Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "# Convert back to labels for better readability\n",
    "y_test_label_names = [idx_to_label[idx] for idx in y_test_encoded]\n",
    "y_pred_label_names = [idx_to_label[idx] for idx in y_pred_encoded]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test_encoded, y_pred_encoded, labels=list(range(num_classes)))\n",
    "\n",
    "print(f\"Confusion matrix shape: {cm.shape}\")\n",
    "print(f\"Total test samples: {len(y_test_encoded)}\")\n",
    "print(f\"Correct predictions: {np.trace(cm)}\")\n",
    "print(f\"Accuracy from confusion matrix: {np.trace(cm) / len(y_test_encoded):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Confusion Matrix (Full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 340 classes, the full confusion matrix is too large to visualize clearly\n",
    "# We'll create a normalized version and show statistics\n",
    "\n",
    "# Normalize confusion matrix (percentages)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cm_normalized = np.nan_to_num(cm_normalized)  # Replace NaN with 0\n",
    "\n",
    "# Create figure with subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Plot raw confusion matrix (log scale for better visibility)\n",
    "cm_log = np.log1p(cm)  # log(1+x) to handle zeros\n",
    "im1 = axes[0].imshow(cm_log, cmap='Blues', aspect='auto')\n",
    "axes[0].set_title(f'Confusion Matrix (Log Scale)\\nAccuracy: {accuracy:.4f}', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Predicted Label', fontsize=12)\n",
    "axes[0].set_ylabel('True Label', fontsize=12)\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "im2 = axes[1].imshow(cm_normalized, cmap='Blues', aspect='auto', vmin=0, vmax=1)\n",
    "axes[1].set_title('Normalized Confusion Matrix\\n(Row-wise percentages)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Predicted Label', fontsize=12)\n",
    "axes[1].set_ylabel('True Label', fontsize=12)\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nNote: Due to the large number of classes (340), individual labels are not shown.\")\n",
    "print(\"The diagonal represents correct predictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Top Confused Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find classes with most confusion (off-diagonal elements)\n",
    "off_diagonal = cm.copy()\n",
    "np.fill_diagonal(off_diagonal, 0)\n",
    "\n",
    "# Get top N most confused classes\n",
    "top_n = 20\n",
    "class_totals = cm.sum(axis=1)\n",
    "class_correct = np.diag(cm)\n",
    "class_errors = class_totals - class_correct\n",
    "\n",
    "# Get indices sorted by error count\n",
    "top_error_indices = np.argsort(class_errors)[-top_n:][::-1]\n",
    "\n",
    "# Create submatrix for top confused classes\n",
    "cm_subset = cm[np.ix_(top_error_indices, top_error_indices)]\n",
    "labels_subset = [idx_to_label[idx] for idx in top_error_indices]\n",
    "\n",
    "# Plot subset confusion matrix\n",
    "plt.figure(figsize=(16, 14))\n",
    "cm_subset_normalized = cm_subset.astype('float') / cm_subset.sum(axis=1)[:, np.newaxis]\n",
    "cm_subset_normalized = np.nan_to_num(cm_subset_normalized)\n",
    "\n",
    "sns.heatmap(cm_subset_normalized, \n",
    "            annot=True, \n",
    "            fmt='.2f', \n",
    "            cmap='Blues',\n",
    "            xticklabels=labels_subset,\n",
    "            yticklabels=labels_subset,\n",
    "            cbar_kws={'label': 'Normalized Count'})\n",
    "\n",
    "plt.title(f'Confusion Matrix - Top {top_n} Most Confused Classes\\n(Normalized by row)', \n",
    "          fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics for top confused classes\n",
    "print(f\"\\nTop {top_n} classes with most errors:\")\n",
    "print(\"=\" * 80)\n",
    "for idx in top_error_indices:\n",
    "    label = idx_to_label[idx]\n",
    "    total = class_totals[idx]\n",
    "    correct = class_correct[idx]\n",
    "    errors = class_errors[idx]\n",
    "    accuracy_class = correct / total if total > 0 else 0\n",
    "    print(f\"{label:30s} | Total: {total:4d} | Correct: {correct:4d} | Errors: {errors:4d} | Acc: {accuracy_class:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Per-Class Accuracy Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate per-class accuracy\n",
    "class_accuracies = []\n",
    "for idx in range(num_classes):\n",
    "    total = cm.sum(axis=1)[idx]\n",
    "    if total > 0:\n",
    "        correct = cm[idx, idx]\n",
    "        accuracy_class = correct / total\n",
    "        class_accuracies.append({\n",
    "            'class_idx': idx,\n",
    "            'label': idx_to_label[idx],\n",
    "            'total_samples': total,\n",
    "            'correct': correct,\n",
    "            'accuracy': accuracy_class\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_acc = pd.DataFrame(class_accuracies)\n",
    "df_acc = df_acc.sort_values('accuracy')\n",
    "\n",
    "# Display statistics\n",
    "print(\"Per-Class Accuracy Statistics:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Mean accuracy: {df_acc['accuracy'].mean():.4f}\")\n",
    "print(f\"Median accuracy: {df_acc['accuracy'].median():.4f}\")\n",
    "print(f\"Std deviation: {df_acc['accuracy'].std():.4f}\")\n",
    "print(f\"\\nBest performing classes:\")\n",
    "print(df_acc.tail(10)[['label', 'total_samples', 'correct', 'accuracy']].to_string(index=False))\n",
    "print(f\"\\nWorst performing classes:\")\n",
    "print(df_acc.head(10)[['label', 'total_samples', 'correct', 'accuracy']].to_string(index=False))\n",
    "\n",
    "# Plot distribution of accuracies\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(df_acc['accuracy'], bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Per-Class Accuracy', fontsize=12)\n",
    "plt.ylabel('Number of Classes', fontsize=12)\n",
    "plt.title('Distribution of Per-Class Accuracies', fontsize=14, fontweight='bold')\n",
    "plt.axvline(df_acc['accuracy'].mean(), color='red', linestyle='--', label=f'Mean: {df_acc[\"accuracy\"].mean():.3f}')\n",
    "plt.axvline(df_acc['accuracy'].median(), color='green', linestyle='--', label=f'Median: {df_acc[\"accuracy\"].median():.3f}')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report\n",
    "class_names = [idx_to_label[i] for i in range(num_classes)]\n",
    "report = classification_report(y_test_encoded, y_pred_encoded, \n",
    "                               target_names=class_names,\n",
    "                               output_dict=True,\n",
    "                               zero_division=0)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Overall Accuracy: {report['accuracy']:.4f}\")\n",
    "print(f\"\\nMacro Average:\")\n",
    "print(f\"  Precision: {report['macro avg']['precision']:.4f}\")\n",
    "print(f\"  Recall: {report['macro avg']['recall']:.4f}\")\n",
    "print(f\"  F1-Score: {report['macro avg']['f1-score']:.4f}\")\n",
    "print(f\"\\nWeighted Average:\")\n",
    "print(f\"  Precision: {report['weighted avg']['precision']:.4f}\")\n",
    "print(f\"  Recall: {report['weighted avg']['recall']:.4f}\")\n",
    "print(f\"  F1-Score: {report['weighted avg']['f1-score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Top-3 Accuracy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate top-3 accuracy\n",
    "print(\"Calculating top-3 accuracy...\")\n",
    "print(\"Note: This requires computing similarities for all classes per image.\")\n",
    "\n",
    "top3_correct = 0\n",
    "\n",
    "for i in tqdm(range(len(X_test_images)), desc=\"Top-3 predictions\"):\n",
    "    img = X_test_images[i]\n",
    "    true_label = y_test_encoded[i]\n",
    "    \n",
    "    # Compute similarities for all classes\n",
    "    similarities = {}\n",
    "    for cls_idx in classifier.classes_:\n",
    "        template_data = classifier.templates[cls_idx]\n",
    "        similarity = classifier._compute_similarity(img, template_data)\n",
    "        similarities[cls_idx] = similarity\n",
    "    \n",
    "    # Get top-3 predictions\n",
    "    top3_pred = sorted(similarities.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "    top3_classes = [cls_idx for cls_idx, _ in top3_pred]\n",
    "    \n",
    "    # Check if true label is in top-3\n",
    "    if true_label in top3_classes:\n",
    "        top3_correct += 1\n",
    "\n",
    "top3_accuracy = top3_correct / len(y_test_encoded)\n",
    "print(f\"\\nTop-3 Accuracy: {top3_accuracy:.4f} ({top3_accuracy*100:.2f}%)\")\n",
    "print(f\"Top-1 Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Improvement: {(top3_accuracy - accuracy):.4f} ({(top3_accuracy - accuracy)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save confusion matrix and results\n",
    "output_dir = Path('results/similarity')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save confusion matrix as numpy array\n",
    "np.save(output_dir / 'confusion_matrix.npy', cm)\n",
    "np.save(output_dir / 'confusion_matrix_normalized.npy', cm_normalized)\n",
    "\n",
    "# Save per-class accuracies\n",
    "df_acc.to_csv(output_dir / 'per_class_accuracy.csv', index=False)\n",
    "\n",
    "# Save summary statistics\n",
    "summary = {\n",
    "    'test_accuracy': float(accuracy),\n",
    "    'test_top3_accuracy': float(top3_accuracy),\n",
    "    'num_test_samples': int(len(y_test_encoded)),\n",
    "    'num_classes': int(num_classes),\n",
    "    'method': method,\n",
    "    'use_sobel': use_sobel,\n",
    "    'mean_per_class_accuracy': float(df_acc['accuracy'].mean()),\n",
    "    'median_per_class_accuracy': float(df_acc['accuracy'].median()),\n",
    "    'std_per_class_accuracy': float(df_acc['accuracy'].std()),\n",
    "    'macro_avg_precision': float(report['macro avg']['precision']),\n",
    "    'macro_avg_recall': float(report['macro avg']['recall']),\n",
    "    'macro_avg_f1': float(report['macro avg']['f1-score']),\n",
    "    'weighted_avg_precision': float(report['weighted avg']['precision']),\n",
    "    'weighted_avg_recall': float(report['weighted avg']['recall']),\n",
    "    'weighted_avg_f1': float(report['weighted avg']['f1-score'])\n",
    "}\n",
    "\n",
    "with open(output_dir / 'evaluation_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\nResults saved to {output_dir}/\")\n",
    "print(f\"  - confusion_matrix.npy\")\n",
    "print(f\"  - confusion_matrix_normalized.npy\")\n",
    "print(f\"  - per_class_accuracy.csv\")\n",
    "print(f\"  - evaluation_summary.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
